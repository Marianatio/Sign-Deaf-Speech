{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up for Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawer = mp.solutions.drawing_utils\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base options for hand and pose detection models\n",
    "hand_base_options = python.BaseOptions(model_asset_path=\"../tasks/hand_landmarker.task\")\n",
    "pose_base_options = python.BaseOptions(model_asset_path=\"../tasks/pose_landmarker.task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for hand detection\n",
    "hand_options = vision.HandLandmarkerOptions(\n",
    "    base_options=hand_base_options,\n",
    "    num_hands=2,\n",
    "    min_hand_detection_confidence=0.6,\n",
    "    min_hand_presence_confidence=0.6,\n",
    "    min_tracking_confidence=0.1,\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    ")\n",
    "\n",
    "# options for pose detection\n",
    "pose_options = vision.PoseLandmarkerOptions(\n",
    "    base_options=pose_base_options,\n",
    "    output_segmentation_masks=True,\n",
    "    min_pose_detection_confidence=0.6,\n",
    "    min_pose_presence_confidence=0.6,\n",
    "    min_tracking_confidence=0.1,\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    ")\n",
    "\n",
    "# create detectors\n",
    "hand_detector = vision.HandLandmarker.create_from_options(hand_options)\n",
    "pose_detector = vision.PoseLandmarker.create_from_options(pose_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Mediapipe Landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_hand_landmark = np.zeros((2, 21, 3))  # right hand and left hand\n",
    "empty_pose_landmark = np.zeros(33 * 3)\n",
    "\n",
    "def to_landmark_data(\n",
    "    hand_results: vision.HandLandmarkerResult, pose_results: vision.PoseLandmarkerResult\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract keypoints from pose and hand results for dataset creation.\n",
    "    \"\"\"\n",
    "    pose_landmark = empty_pose_landmark\n",
    "    hand_landmark = empty_hand_landmark\n",
    "\n",
    "    if pose_results.pose_world_landmarks:\n",
    "        pose_landmark = np.array(\n",
    "            [[lm.x, lm.y, lm.z] for lm in pose_results.pose_world_landmarks[0]]\n",
    "        ).flatten()\n",
    "\n",
    "    # if no hand results are available, return the empty hand keypoints\n",
    "    # and concatenate it with face and pose keypoints\n",
    "    if not hand_results:\n",
    "        return np.concatenate([pose_landmark, hand_landmark.flatten()])\n",
    "\n",
    "    # iterate over the detected hand landmarks\n",
    "    for index, hlm in enumerate(hand_results.hand_world_landmarks):\n",
    "        # determine the hand index (0 for right hand, 1 for left hand) using handedness information\n",
    "        handedness = hand_results.handedness[index][0].index\n",
    "\n",
    "        # extract the keypoints for the current hand and assign them to the appropriate index\n",
    "        hand_landmark[handedness] = np.array([[lm.x, lm.y, lm.z] for lm in hlm])\n",
    "\n",
    "    return np.concatenate([pose_landmark, hand_landmark.flatten()])\n",
    "\n",
    "LandmarkList = landmark_pb2.NormalizedLandmarkList  # aliases for landmark types\n",
    "NormalizedLandmark = landmark_pb2.NormalizedLandmark  # aliases for landmark types\n",
    "\n",
    "\n",
    "def to_landmark_list(landmarks):\n",
    "    \"\"\"\n",
    "    Create a LandmarkList from a list of landmarks or fill with empty values if no landmarks are provided.\n",
    "    \"\"\"\n",
    "    return LandmarkList(\n",
    "        landmark=([NormalizedLandmark(x=lm.x, y=lm.y, z=lm.z) for lm in landmarks])\n",
    "    )\n",
    "\n",
    "\n",
    "empty_pose_landmarks = to_landmark_list(\n",
    "    [NormalizedLandmark(x=0.0, y=0.0, z=0.0) for _ in range(33 * 4)]\n",
    ")\n",
    "\n",
    "empty_hand_landmarks = to_landmark_list(\n",
    "    [NormalizedLandmark(x=0.0, y=0.0, z=0.0) for _ in range(21 * 3)]\n",
    ")\n",
    "\n",
    "\n",
    "def to_drawing_landmark(hand_results, pose_results):\n",
    "    \"\"\"\n",
    "    Convert pose and hand landmarks to LandmarkList for drawing.\n",
    "    \"\"\"\n",
    "    pose_landmarks = (\n",
    "        to_landmark_list(pose_results.pose_landmarks[0])\n",
    "        if pose_results.pose_landmarks\n",
    "        else empty_pose_landmarks\n",
    "    )\n",
    "\n",
    "    hand_landmarks = [empty_hand_landmarks, empty_hand_landmarks]\n",
    "\n",
    "    if not hand_results:\n",
    "        return pose_landmarks, None\n",
    "\n",
    "    # iterate over the detected hand landmarks\n",
    "    for index, hand_landmark in enumerate(hand_results.hand_landmarks):\n",
    "        # determine the hand index (0 for right hand, 1 for left hand) using handedness information\n",
    "        handedness = hand_results.handedness[index][0].index\n",
    "\n",
    "        # extract the keypoints for the current hand and assign them to the appropriate index\n",
    "        hand_landmarks[handedness] = to_landmark_list(hand_landmark)\n",
    "\n",
    "    return pose_landmarks, hand_landmarks\n",
    "\n",
    "\n",
    "def draw_landmark(image, hand_landmarks, pose_landmarks):\n",
    "    \"\"\"\n",
    "    Draw detected landmarks on the image.\n",
    "    \"\"\"\n",
    "    drawer.draw_landmarks(\n",
    "        image,\n",
    "        pose_landmarks,\n",
    "        mp.solutions.pose.POSE_CONNECTIONS,\n",
    "        drawer.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=3),\n",
    "        drawer.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2),\n",
    "    )\n",
    "\n",
    "    if not hand_landmarks:\n",
    "        return\n",
    "\n",
    "    for hand_landmarks in hand_landmarks:\n",
    "        drawer.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp.solutions.hands.HAND_CONNECTIONS,\n",
    "            drawer.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=2),\n",
    "            drawer.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action lables\n",
    "ACTIONS = np.array([\n",
    "    \"apa\", \"aku\", \"kamu\"\n",
    "])\n",
    "\n",
    "val_path = \"../../storage/datasets/raw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_version=None):\n",
    "    model_dir = \"../../storage/models/keras\"\n",
    "    prefix = \"signdeafspeech_sds_v_\"\n",
    "\n",
    "    if model_version:\n",
    "        version = f\"{prefix}{model_version}.keras\"\n",
    "        ks_file = os.path.join(model_dir, version)\n",
    "\n",
    "        model = tf.keras.models.load_model(ks_file)\n",
    "\n",
    "        return version, model\n",
    "\n",
    "    model_files = os.listdir(model_dir)\n",
    "\n",
    "    # filter model files by filename prefix\n",
    "    versions = [file for file in model_files if file.startswith(prefix)]\n",
    "\n",
    "    # extract version numbers from filenames\n",
    "    versions = [file.split(\"_\")[-1] for file in versions]\n",
    "\n",
    "    # convert version numbers to tuples of integers for comparison\n",
    "    versions_int = [tuple(map(int, v.split(\".\")[0])) for v in versions]\n",
    "\n",
    "    # find the index of the latest version\n",
    "    latest_index = versions_int.index(max(versions_int))\n",
    "\n",
    "    # load the latest model\n",
    "    latest_model_path = model_files[latest_index]\n",
    "\n",
    "    model = tf.keras.models.load_model(os.path.join(model_dir, latest_model_path))\n",
    "\n",
    "    return latest_model_path, model\n",
    "\n",
    "\n",
    "v, model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'using model signdeafspeech_sds_v_006.keras'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"using model {v}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">900</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m225\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m225\u001b[0m)        │           \u001b[38;5;34m900\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m7,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">548,099</span> (2.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m548,099\u001b[0m (2.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">182,389</span> (712.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m182,389\u001b[0m (712.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> (3.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m930\u001b[0m (3.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">364,780</span> (1.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m364,780\u001b[0m (1.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import concurrent.futures\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, image):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # convert into mediapipe numpy type support uint8, uint16, or float32\n",
    "    image = np.fliplr(image)\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    # convert cv image to mediapipe image format before being passed to detectors\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "\n",
    "    hand_results = hand_detector.detect(image=mp_image)\n",
    "    pose_results = pose_detector.detect(image=mp_image)\n",
    "\n",
    "    landmarks = to_landmark_data(hand_results, pose_results)\n",
    "\n",
    "    return frame, landmarks, time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_video(vid):\n",
    "    clip = VideoFileClip(vid)\n",
    "\n",
    "    avg_exec_time = []\n",
    "\n",
    "    predictions = []\n",
    "    sequences = []\n",
    "\n",
    "    sentence = []\n",
    "    threshold = 0.99\n",
    "    skip_word = \"_\"\n",
    "\n",
    "    results = []\n",
    "    batch_size = 60\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_frame = {\n",
    "            executor.submit(\n",
    "                process_frame,\n",
    "                frame,\n",
    "                image,\n",
    "            ): frame\n",
    "            for frame, image in enumerate(clip.iter_frames(fps=clip.fps))\n",
    "        }\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_frame):\n",
    "            frame, landmarks, exec_time = future.result()\n",
    "            avg_exec_time.append(exec_time)\n",
    "\n",
    "            if landmarks is not None:\n",
    "                results.append((frame, landmarks))\n",
    "\n",
    "    clip.close()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # sort the results by frame number to ensure the order is correct\n",
    "    results.sort(key=lambda x: x[0])\n",
    "\n",
    "    for _, landmarks in results:\n",
    "        sequences.append(landmarks)\n",
    "\n",
    "        if len(sequences) < batch_size:\n",
    "            continue\n",
    "\n",
    "        # ensure correct input shape by adding an extra dimension for batch size\n",
    "        batch_motion = np.expand_dims(np.stack(sequences[-batch_size:]), axis=0)\n",
    "\n",
    "        # predict the motion\n",
    "        result = model.predict(batch_motion, verbose=0)[0]\n",
    "\n",
    "        # get the predicted class and its confidence\n",
    "        predicted = np.argmax(result)\n",
    "        confidence = result[predicted]\n",
    "\n",
    "        # append to the predictions and accuracies list\n",
    "        predictions.append(predicted)\n",
    "\n",
    "        # only keep the last 20 predictions and their accuracies\n",
    "        # predictions = predictions[-20:]\n",
    "\n",
    "        predicted_sentence = ACTIONS[predicted]\n",
    "\n",
    "        # determine most frequent prediction\n",
    "        most_frequent_prediction = np.bincount(predictions[-10:]).argmax()\n",
    "        print(most_frequent_prediction, \"\\t\", result[predicted], \"\\t\", predicted_sentence)\n",
    "\n",
    "        if most_frequent_prediction != predicted:\n",
    "            continue\n",
    "\n",
    "        elif confidence < threshold:\n",
    "            continue\n",
    "\n",
    "        elif predicted_sentence == skip_word:\n",
    "            continue\n",
    "\n",
    "        elif not sentence or predicted_sentence != sentence[-1]:\n",
    "            # print(confidence, \"\\t\", predicted_sentence, \"\\t\\t\", result)\n",
    "            sentence.append(predicted_sentence)\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    return (\n",
    "        sentence,\n",
    "        len(results),\n",
    "        {\n",
    "            \"pred_exec_time\": end_time,\n",
    "            \"avg_exec_time\": avg_exec_time,\n",
    "            \"total_exec_time\": sum(avg_exec_time),\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t 0.9986619 \t kamu\n",
      "2 \t 0.99899167 \t kamu\n",
      "2 \t 0.99892116 \t kamu\n",
      "2 \t 0.9987853 \t kamu\n",
      "2 \t 0.9985593 \t kamu\n",
      "2 \t 0.9986652 \t kamu\n",
      "2 \t 0.99866736 \t kamu\n",
      "2 \t 0.9985654 \t kamu\n",
      "2 \t 0.998635 \t kamu\n",
      "2 \t 0.99901485 \t kamu\n",
      "2 \t 0.9991365 \t kamu\n",
      "2 \t 0.9992329 \t kamu\n",
      "2 \t 0.9993679 \t kamu\n",
      "2 \t 0.99951303 \t kamu\n",
      "2 \t 0.99961346 \t kamu\n",
      "2 \t 0.99965787 \t kamu\n",
      "2 \t 0.9997441 \t kamu\n",
      "2 \t 0.9998048 \t kamu\n",
      "2 \t 0.9998565 \t kamu\n",
      "2 \t 0.9998597 \t kamu\n",
      "2 \t 0.9998977 \t kamu\n",
      "2 \t 0.99990714 \t kamu\n",
      "2 \t 0.99993265 \t kamu\n",
      "2 \t 0.9999304 \t kamu\n",
      "2 \t 0.9999503 \t kamu\n",
      "2 \t 0.99995184 \t kamu\n",
      "2 \t 0.99996483 \t kamu\n",
      "2 \t 0.9999578 \t kamu\n",
      "2 \t 0.99996936 \t kamu\n",
      "2 \t 0.99996555 \t kamu\n",
      "2 \t 0.9999747 \t kamu\n",
      "2 \t 0.9999691 \t kamu\n",
      "2 \t 0.9999777 \t kamu\n",
      "2 \t 0.9999746 \t kamu\n",
      "2 \t 0.9999826 \t kamu\n",
      "2 \t 0.99997675 \t kamu\n",
      "2 \t 0.999984 \t kamu\n",
      "2 \t 0.9999809 \t kamu\n",
      "2 \t 0.9999875 \t kamu\n",
      "2 \t 0.9999845 \t kamu\n",
      "2 \t 0.9999895 \t kamu\n",
      "2 \t 0.9999882 \t kamu\n",
      "2 \t 0.999992 \t kamu\n",
      "2 \t 0.9999901 \t kamu\n",
      "2 \t 0.99999297 \t kamu\n",
      "2 \t 0.9999924 \t kamu\n",
      "2 \t 0.9999944 \t kamu\n",
      "2 \t 0.9999939 \t kamu\n",
      "2 \t 0.99999547 \t kamu\n",
      "2 \t 0.9999956 \t kamu\n",
      "2 \t 0.9999963 \t kamu\n",
      "2 \t 0.9999957 \t kamu\n",
      "2 \t 0.99999654 \t kamu\n",
      "2 \t 0.99999654 \t kamu\n",
      "2 \t 0.99999714 \t kamu\n",
      "2 \t 0.99999666 \t kamu\n",
      "2 \t 0.999997 \t kamu\n",
      "2 \t 0.9999968 \t kamu\n",
      "2 \t 0.99999666 \t kamu\n",
      "2 \t 0.99999523 \t kamu\n",
      "2 \t 0.9999945 \t kamu\n",
      "2 \t 0.9999933 \t kamu\n",
      "2 \t 0.9999933 \t kamu\n",
      "2 \t 0.99999166 \t kamu\n",
      "2 \t 0.99999094 \t kamu\n",
      "2 \t 0.9999896 \t kamu\n",
      "2 \t 0.99998736 \t kamu\n",
      "2 \t 0.999984 \t kamu\n",
      "2 \t 0.9999802 \t kamu\n",
      "2 \t 0.9999795 \t kamu\n",
      "2 \t 0.9999788 \t kamu\n",
      "2 \t 0.9999788 \t kamu\n",
      "2 \t 0.99997544 \t kamu\n",
      "2 \t 0.99997497 \t kamu\n",
      "2 \t 0.9999691 \t kamu\n",
      "2 \t 0.99996555 \t kamu\n",
      "2 \t 0.99995744 \t kamu\n",
      "2 \t 0.99995923 \t kamu\n",
      "2 \t 0.9999585 \t kamu\n",
      "2 \t 0.9999628 \t kamu\n",
      "2 \t 0.9999596 \t kamu\n",
      "2 \t 0.999959 \t kamu\n",
      "2 \t 0.9999535 \t kamu\n",
      "2 \t 0.9999528 \t kamu\n",
      "2 \t 0.9999498 \t kamu\n",
      "2 \t 0.9999566 \t kamu\n",
      "2 \t 0.9999566 \t kamu\n",
      "2 \t 0.9999633 \t kamu\n",
      "2 \t 0.99995744 \t kamu\n",
      "2 \t 0.9999597 \t kamu\n",
      "2 \t 0.9999566 \t kamu\n",
      "2 \t 0.9999579 \t kamu\n",
      "2 \t 0.99995303 \t kamu\n",
      "2 \t 0.9999602 \t kamu\n",
      "2 \t 0.999962 \t kamu\n",
      "2 \t 0.9999676 \t kamu\n",
      "2 \t 0.99996066 \t kamu\n",
      "2 \t 0.9999598 \t kamu\n",
      "2 \t 0.99995875 \t kamu\n",
      "2 \t 0.9999604 \t kamu\n",
      "2 \t 0.9999548 \t kamu\n",
      "2 \t 0.9999614 \t kamu\n",
      "2 \t 0.9999634 \t kamu\n",
      "==================================================\n",
      "Total frame calculated: 162\n",
      "Total prediction execution: 7.275776386260986\n",
      "Average execution time per frame: 0.42105494163654467\n",
      "Predicted sentence: ['kamu']\n"
     ]
    }
   ],
   "source": [
    "sentence, frame, exec_time = predict_from_video(\"./demo/kamu.mp4\")\n",
    "true_sentence_1 = [\"aku\", \"apa\", \"kamu\", \"bagaimana\"]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Total frame calculated:\", frame)\n",
    "print(\"Total prediction execution:\", np.mean(exec_time[\"pred_exec_time\"]))\n",
    "print(\"Average execution time per frame:\", np.mean(exec_time[\"avg_exec_time\"]))\n",
    "print(\"Predicted sentence:\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sentence_1 == sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t 0.99545836 \t kamu\n",
      "2 \t 0.98623276 \t kamu\n",
      "2 \t 0.9855251 \t kamu\n",
      "2 \t 0.9300357 \t kamu\n",
      "2 \t 0.88162637 \t kamu\n",
      "2 \t 0.6730666 \t kamu\n",
      "2 \t 0.6350211 \t kamu\n",
      "2 \t 0.67226475 \t aku\n",
      "2 \t 0.78413755 \t aku\n",
      "2 \t 0.9173877 \t aku\n",
      "2 \t 0.921875 \t aku\n",
      "1 \t 0.97224975 \t aku\n",
      "1 \t 0.9818364 \t aku\n",
      "1 \t 0.99299 \t aku\n",
      "1 \t 0.993859 \t aku\n",
      "1 \t 0.99736327 \t aku\n",
      "1 \t 0.9981616 \t aku\n",
      "1 \t 0.99913245 \t aku\n",
      "1 \t 0.9991786 \t aku\n",
      "1 \t 0.9996525 \t aku\n",
      "1 \t 0.9997453 \t aku\n",
      "1 \t 0.99986887 \t aku\n",
      "1 \t 0.999884 \t aku\n",
      "1 \t 0.99994016 \t aku\n",
      "1 \t 0.9999553 \t aku\n",
      "1 \t 0.9999757 \t aku\n",
      "1 \t 0.99997723 \t aku\n",
      "1 \t 0.9999883 \t aku\n",
      "1 \t 0.99999106 \t aku\n",
      "1 \t 0.9999945 \t aku\n",
      "1 \t 0.9999951 \t aku\n",
      "1 \t 0.99999726 \t aku\n",
      "1 \t 0.999998 \t aku\n",
      "1 \t 0.9999987 \t aku\n",
      "1 \t 0.9999988 \t aku\n",
      "1 \t 0.99999917 \t aku\n",
      "1 \t 0.9999994 \t aku\n",
      "1 \t 0.9999995 \t aku\n",
      "1 \t 0.9999995 \t aku\n",
      "1 \t 0.99999964 \t aku\n",
      "1 \t 0.99999964 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.9999999 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999976 \t aku\n",
      "1 \t 0.99999964 \t aku\n",
      "1 \t 0.99999964 \t aku\n",
      "1 \t 0.99999964 \t aku\n",
      "1 \t 0.99999964 \t aku\n",
      "1 \t 0.9999995 \t aku\n",
      "1 \t 0.9999994 \t aku\n",
      "1 \t 0.9999993 \t aku\n",
      "1 \t 0.99999917 \t aku\n",
      "1 \t 0.9999989 \t aku\n",
      "1 \t 0.9999988 \t aku\n",
      "1 \t 0.99999833 \t aku\n",
      "1 \t 0.9999982 \t aku\n",
      "1 \t 0.9999974 \t aku\n",
      "1 \t 0.999997 \t aku\n",
      "1 \t 0.9999958 \t aku\n",
      "1 \t 0.99999535 \t aku\n",
      "==================================================\n",
      "Total frame calculated: 164\n",
      "Total prediction execution: 8.118151664733887\n",
      "Average execution time per frame: 0.4550664337669931\n",
      "Predicted sentence: ['kamu', 'aku']\n"
     ]
    }
   ],
   "source": [
    "sentence, frame, exec_time = predict_from_video(\"./demo/aku.mp4\")\n",
    "true_sentence_2 = [\"halo\", \"selamat pagi\", \"kamu\", \"bagaimana\"]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Total frame calculated:\", frame)\n",
    "print(\"Total prediction execution:\", np.mean(exec_time[\"pred_exec_time\"]))\n",
    "print(\"Average execution time per frame:\", np.mean(exec_time[\"avg_exec_time\"]))\n",
    "print(\"Predicted sentence:\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sentence_2 == sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \t 0.9986619 \t kamu\n",
      "2 \t 0.99899167 \t kamu\n",
      "2 \t 0.99892116 \t kamu\n",
      "2 \t 0.9987853 \t kamu\n",
      "2 \t 0.9985593 \t kamu\n",
      "2 \t 0.9986652 \t kamu\n",
      "2 \t 0.99866736 \t kamu\n",
      "2 \t 0.9985654 \t kamu\n",
      "2 \t 0.998635 \t kamu\n",
      "2 \t 0.99901485 \t kamu\n",
      "2 \t 0.9991365 \t kamu\n",
      "2 \t 0.9992329 \t kamu\n",
      "2 \t 0.9993679 \t kamu\n",
      "2 \t 0.99951303 \t kamu\n",
      "2 \t 0.99961346 \t kamu\n",
      "2 \t 0.99965787 \t kamu\n",
      "2 \t 0.9997441 \t kamu\n",
      "2 \t 0.9998048 \t kamu\n",
      "2 \t 0.9998565 \t kamu\n",
      "2 \t 0.9998597 \t kamu\n",
      "2 \t 0.9998977 \t kamu\n",
      "2 \t 0.99990714 \t kamu\n",
      "2 \t 0.99993265 \t kamu\n",
      "2 \t 0.9999304 \t kamu\n",
      "2 \t 0.9999503 \t kamu\n",
      "2 \t 0.99995184 \t kamu\n",
      "2 \t 0.99996483 \t kamu\n",
      "2 \t 0.9999578 \t kamu\n",
      "2 \t 0.99996936 \t kamu\n",
      "2 \t 0.99996555 \t kamu\n",
      "2 \t 0.9999747 \t kamu\n",
      "2 \t 0.9999691 \t kamu\n",
      "2 \t 0.9999777 \t kamu\n",
      "2 \t 0.9999746 \t kamu\n",
      "2 \t 0.9999826 \t kamu\n",
      "2 \t 0.99997675 \t kamu\n",
      "2 \t 0.999984 \t kamu\n",
      "2 \t 0.9999809 \t kamu\n",
      "2 \t 0.9999875 \t kamu\n",
      "2 \t 0.9999845 \t kamu\n",
      "2 \t 0.9999895 \t kamu\n",
      "2 \t 0.9999882 \t kamu\n",
      "2 \t 0.999992 \t kamu\n",
      "2 \t 0.9999901 \t kamu\n",
      "2 \t 0.99999297 \t kamu\n",
      "2 \t 0.9999924 \t kamu\n",
      "2 \t 0.9999944 \t kamu\n",
      "2 \t 0.9999939 \t kamu\n",
      "2 \t 0.99999547 \t kamu\n",
      "2 \t 0.9999956 \t kamu\n",
      "2 \t 0.9999963 \t kamu\n",
      "2 \t 0.9999956 \t kamu\n",
      "2 \t 0.99999654 \t kamu\n",
      "2 \t 0.99999654 \t kamu\n",
      "2 \t 0.999997 \t kamu\n",
      "2 \t 0.9999963 \t kamu\n",
      "2 \t 0.99999666 \t kamu\n",
      "2 \t 0.9999958 \t kamu\n",
      "2 \t 0.99999523 \t kamu\n",
      "2 \t 0.9999924 \t kamu\n",
      "2 \t 0.9999907 \t kamu\n",
      "2 \t 0.9999869 \t kamu\n",
      "2 \t 0.9999862 \t kamu\n",
      "2 \t 0.99998116 \t kamu\n",
      "2 \t 0.9999777 \t kamu\n",
      "2 \t 0.9999678 \t kamu\n",
      "2 \t 0.9999553 \t kamu\n",
      "2 \t 0.9999349 \t kamu\n",
      "2 \t 0.99991596 \t kamu\n",
      "2 \t 0.9999014 \t kamu\n",
      "2 \t 0.99989533 \t kamu\n",
      "2 \t 0.9998908 \t kamu\n",
      "2 \t 0.9998579 \t kamu\n",
      "2 \t 0.9998356 \t kamu\n",
      "2 \t 0.9997584 \t kamu\n",
      "2 \t 0.9997106 \t kamu\n",
      "2 \t 0.9996202 \t kamu\n",
      "2 \t 0.9995851 \t kamu\n",
      "2 \t 0.9995689 \t kamu\n",
      "2 \t 0.999602 \t kamu\n",
      "2 \t 0.9995419 \t kamu\n",
      "2 \t 0.99948174 \t kamu\n",
      "2 \t 0.9993383 \t kamu\n",
      "2 \t 0.99929416 \t kamu\n",
      "2 \t 0.9992637 \t kamu\n",
      "2 \t 0.9992719 \t kamu\n",
      "2 \t 0.9993049 \t kamu\n",
      "2 \t 0.99940753 \t kamu\n",
      "2 \t 0.9993211 \t kamu\n",
      "2 \t 0.9993129 \t kamu\n",
      "2 \t 0.999183 \t kamu\n",
      "2 \t 0.9991523 \t kamu\n",
      "2 \t 0.9990902 \t kamu\n",
      "2 \t 0.9990957 \t kamu\n",
      "2 \t 0.9992023 \t kamu\n",
      "2 \t 0.99930966 \t kamu\n",
      "2 \t 0.9992173 \t kamu\n",
      "2 \t 0.99915695 \t kamu\n",
      "2 \t 0.9990796 \t kamu\n",
      "2 \t 0.99906427 \t kamu\n",
      "2 \t 0.9990188 \t kamu\n",
      "2 \t 0.99903166 \t kamu\n",
      "2 \t 0.99918646 \t kamu\n",
      "==================================================\n",
      "Total frame calculated: 162\n",
      "Total prediction execution: 6.511943817138672\n",
      "Average execution time per frame: 0.497412273913254\n",
      "Predicted sentence: ['kamu']\n"
     ]
    }
   ],
   "source": [
    "sentence, frame, exec_time = predict_from_video(\"./demo/kamu.mp4\")\n",
    "true_sentence_3 = [\"apa\", \"aku\", \"kamu\"]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Total frame calculated:\", frame)\n",
    "print(\"Total prediction execution:\", np.mean(exec_time[\"pred_exec_time\"]))\n",
    "print(\"Average execution time per frame:\", np.mean(exec_time[\"avg_exec_time\"]))\n",
    "print(\"Predicted sentence:\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sentence_3 == sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
